# DOCKER

I summarize here notes taken while learning about Docker.
These notes relate to the learning project I created, it can be found [here](https://github.com/abmesamesa/learning/tree/master/docker).

## INTRODUCTION

Install 
- https://docs.docker.com/engine/install/ubuntu/

Container using unix system capabilities such as "cgroups" and "namespaces" to limit ressources and visibility of processes running in a given machine. Common interface to run applications.

## BASIC IMAGE ADMINISTRATION

Example: Creating a container based on ubuntu image. It creates a new container from zero in mode interactive.
```
docker run -it ubuntu
```
Example: Listing containers
```
docker ps
```
Example: Reading logs of an image
```
docker logs [container id]
```
Example: Stopping an image
```
docker stop [container id]
```
Example: Reusing an existing container without recreation.
It shows the containers, both active and inactive
```
docker ps -a
```
It starts a container inactive
```
docker start -i [container id]
```
Example: Removing an existing container.
```
docker rm [container id]
```
Example: Listing existing images
```
docker images
```
Repository of docker images 
- https://hub.docker.com/explore

## DOCKERFILE

- https://docs.docker.com/engine/reference/builder/
- https://docs.docker.com/develop/develop-images/dockerfile_best-practices/

A specification of the behavior and content of an image. Defining the steps needed to create the image and run it.

## BUILD AND RUN EXAMPLE

Dockerfile content
```
FROM php:7.2-apache

COPY index.php /var/www/html/
```
Here index.php is a simple hello world in the same folder as the docker image and we are going to copy it into a folder in the container.

Build and run
```
docker build -t [docker image name] [docker context path] [-f docker file path]
docker run --rm -p 8000:80 -it [image name]
```

`--rm` removes the container once the instance is stopped  
`-p` maps the ports: local 8000 mapped to 80 within the container

Verifying it is working
```
curl -i localhost:8000/
```

## DOCKER DIRECTIVES

`FROM image` from which we would like to create ours. Can be FROM scratch or FROM ubuntu etc.  
`ADD` copy a file from the outside into the container (could be an url)  
`COPY` copy a file from the outside (path in the context of the build execution) into the container  
`RUN` run a command in the container (install something for instance)  
`ENTRYPOINT` by default docker defines one. Always executed when performing a docker run. The default is ENTRYPOINT ["/bin/sh", "-c"]. So whatever CMD is defined becomes an argument of this entrypoint. Can be overwrite in the command line with the flag -entrypoint.  
`CMD` the command being run when the container is up (after docker run). For instance CMD ["/bin/bash"] to get a shell ready after running an ubuntu image. This is passed to the entrypoint as parameter to be executed. If it is not defined in the Dockerfile, we can also pass it as argument of the docker run command (docker run my-image /bin/bash)  
`LABEL` allows creating labels and then ask docker this metadata about the image

## ENV VARIABLES

Allows to define an env variable in a dockerfile and then overwrite it in runtime.

For instance, we can define a variable `ENV DISPLAY_ERRORS="On"` within our dockerfile and then use it in a "php.ini" file to hydrate the content of `display_errors = "${DISPLAY_ERRORS}"`. The docker run can overwrite its default value with `--env DISPLAY_ERRORS=Off`

## DOCKER FILES BEST PRACTICES

### Cache

If we execute the same docker build command twice, the second one would be faster and the output would contain steps with "---> Using cache" which means that this step is already performed and if it is won't be repeat it.

If one of the steps changes, all the steps afterwards are executed again instead of being considered cached.

We should put the directives that changes often after the instructions that should change little so we can take adventage of the cache system.

### Combine RUN sentences into one
```
RUN pecl install xdebug-2.6.0
RUN docker-php-ext-enable xdebug
RUN docker-php-ext-install pdo pdo_mysql
```
vs
```
RUN pecl install xdebug-2.6.0 \
&& docker-php-ext-enable xdebug \
&& docker-php-ext-install pdo pdo_mysql
```
It will take less space in disk as 3 steps would be combined into 1.

### Multi-stage build

We would like to have images with only the code and dependencies that we need to run the application (more secured and less disk space needed).

One dockerfile with multi-stage (multiple FROM directives) can achieve that. We can for instance have an stage to install composer dependencies and then another one to install the system dependencies and copy the code.

### Versioning images

Docker uses "latest" as the version name by default. We may use a version tag to clearly identify a concrete version. For instance we can use the git commit to identify an image version or semantic versioning (1.0.1 ...)

## EXECUTING DOCKER APPLICATIONS

### Exposing ports

It is possible to define the port of the container that will be expose with the option -p or -P
```
docker run --rm -p 8000:80 -it [image name] # maps port 80 of the container to port 8000 of the machine.
docker run --rm -P -it [image name] # maps all exposed ports of the image (EXPOSE directive) and maps a random port on the machine. I can see the asignd port with docker ps
docker run --rm -p 80 -it [image name] # maps port 80 of the container to random port of the machine. I can see the asignd port with docker ps
```

### Restart docker containers automatically
```
docker run -p 8000:80 --restart=always -it [image name]
```
We can update the restart value
```
sudo docker update --restart=no [container id]
```

### Limiting CPU and memory (cgroups)
```
--memory=500m # limiting the container up to 500 megabytes
--cpus=1.5 # limiting cpu usage to 1.5 cores
--cpu-shares # 2 containers fighting for ressources in an instance can share cpu according to theirs respective weight
```

### Persisting data

Docker can create volumes that are not deleted even if we destroy the container. So they are suitable for creating databases.
```
docker run -it --name volume-test -v /data ubuntu
```
The command above runs an ubuntu image called volume-test and creates a volume mounted in /data in the container and mapped to a real folder in my computer.
```
sudo docker inspect -f "{{json .Mounts}}" [image name] | jq . # let us know where the volume is.
```
I can also create a volume
```
sudo docker volume create volume-test
```
Then, associate it to a given container
```
docker run -it --name volume-test -v volume-test:/data ubuntu
```
I can define the path of the volume instead of creating one
```
docker run -it --name volume-test -v $PWD:/data ubuntu
```
Interestingly we can use volumes to map the code so that the changes are available inmmediatly without rebuilding the container like this
```
docker run -it -p 8000:80 -v $PWD:/var/www/html php:7.2-apache
```
We can define volumes in the dockerfile `VOLUME /data`

## DOCKER COMPOSE

Orchestrates multiple containers in development time.

It adds an abstraction layer for docker commands. We can define the configuration in a yaml file and then docker-compose will performs a build and run in a much simpler manner for a person who does not know the details of the container.
```
docker-compose up # run the services defined within the folder
docker-compose ps # containers being run within the folder
docker-compose logs -f [service name] # shows logs of a given service (services are named in the docker-compose file)
docker-compose top # shows the processes running
docker-compose up -d # run the services in background (detached mode)
docker-compose stop # stop containers, but they remain
docker-compose down # deletes containers, data is lost unless in a volume
docker-compose up --build # the build is made only the first time, we can force the build each time
```
### Multiple containers with docker-compose

We can define multiple services within a docker compose file.
For example one service for the app, one service for the database and one for the data visualisation tool.
Each one is visible to the others

### Environment variables

I can define env variables in a docker compose file without assignation, so that they will take the value of the corresponding environmental variable in the system. The system of CI/CD will then set env variables.

I can create an .env file (not versioned) and docker will take those by default.

## Networking

We can put each service in network so for instance we want one service to be able to talk only to another one.

I can also connect my services to external networks created outside my docker compose file.

## DOCKER IN PRODUCTION

Do not use docker in production for stateful services. Containerizing your database can be tricky between instances or cause data loss even using volumes. For that matter might be better choice Kubernetes. Otherwise, use only your application service in production.

For instance, you can publish your docker image to your aws or github or dockerhub etc registry and then pull the image in your production instance during the CI/CD pipeline.

## COMMAND LINE

Other command line interesting actions
```
docker info
docker ps -a
docker images
docker build -t "docker-hello-world" /path/to/context/dockerfile -f DockerfilePathAndName
docker run --rm --env DISPLAY_ERRORS=Off -p 8000:80 -it "docker-hello-world"
docker rm $(docker ps -a -f status=exited -q) # removes all exited containers
docker rmi $(docker images -a -q) # removes all images
sudo docker exec -it [container id] bash # it execute the command bash in a given container
sudo docker run --rm --env DISPLAY_ERRORS=Off --restart=always -p 8000:80 -it "hello-docker" # restart the container automatically, incompatible with --rm
sudo docker inspect -f "{{json .Mounts}}" [image name] | jq . # shows info about the mounting points of volumes
sudo docker volume ls # listing volumes
docker pull [image name] # will pull the changes of an image from its repository
docker network ls # listing all the available networks
```
